# data-processing-ratelimiting
processing big data by implementing node js streams and rate-limiting strategy.

data is the most important thing for an application and it needs to be handled correctly, in this project I have used node js built in streams to stream 
data from the server/webapi to client side. server limits the requests to 100 or 10 per second, in order to respect server's ratelimiting function we can 
integrate data in such a way so that it respects the server. This implementation will make the server process data efficiently and there will be less load on 
the server. Streams are the most powerful tools in node js, we can process data on demand, filter and map it.
